import numpy as np
import matplotlib.pyplot as plt

x_train = np.array(
    [
        [10, 50],
        [20, 30],
        [25, 30],
        [20, 60],
        [15, 70],
        [40, 40],
        [30, 45],
        [20, 45],
        [40, 30],
        [7, 35],
    ]
)  # начальные данные
y_train = np.array([-1, 1, 1, -1, -1, 1, 1, -1, 1, -1])  # ответы

n_train = len(x_train)  # размер обучающей выборки(размер данных для обучения)
w = [0, -1]  # начальное значение вектора w(w - весы)(какие-то базовые значения)
a = lambda x: np.sign(
    x[0] * w[0] + x[1] * w[1]
)  # решающее правило(правило для получение ответа(y))
N = 50  # максимальное число итераций(число проходов в обучении)
L = 0.1  # шаг изменения веса(шаг изменения для весов(веса))
e = 0.1  # небольшая добавка для w0 чтобы был зазор между разделяющей линией и граничным образом(не обязательное значение)

last_error_index = (
    -1
)  # индекс последнего ошибочного наблюдения(для работы с переменной e)

for n in range(N):
    for i in range(n_train):  # перебор по наблюдениям(обучающим данным)
        if (
            y_train[i] * a(x_train[i]) < 0
        ):  # если ошибка классификации(тоесть сравнение значения ответа(y_train) и ответа по правилу нейросети(a))(в данном случае происходит проверка на отрицательность\положительность обоих значений, тк у нас только два возможных ответа [-1, 1]),
            w[0] = (
                w[0] + L * y_train[i]
            )  # то корректировка веса w0(w1 не принимает участие в этом тк она имеет костантное значение(объясняется математически))
            last_error_index = i  # индекс последней ошибки классификации

    Q = sum(
        [1 for i in range(n_train) if y_train[i] * a(x_train[i]) < 0]
    )  # расчёт качества нашей нейросети(проверка всех вариантов на ошибочность(сумма должна быть равна нулю и тогда ошибок не возникло))
    if Q == 0:  # показатель качества классификации (число ошибок)
        break  # остановка, если все верно классифицируем

if (
    last_error_index > -1
):  # если имела место быть ошибка классификации(очень близко к всегда)
    w[0] = (
        w[0] + e * y_train[last_error_index]
    )  # производим смещение для предотвращения наложения линии на наши начальные данные

print(w)  # вывод наших весов

line_x = list(
    range(max(x_train[:, 0]))
)  # формирование графика разделяющей линии(x_train[:, 0] это принцип записи(выборки) у массивов в numpy что означает для двумерного массива взять все данные в первом измерении двумерного массива и взять 0-е данные во втором измерении)
line_y = [w[0] * x for x in line_x]

x_0 = x_train[y_train == 1]  # формирование точек для 1-го
x_1 = x_train[y_train == -1]  # и 2-го классов

plt.scatter(x_0[:, 0], x_0[:, 1], color="red")
plt.scatter(x_1[:, 0], x_1[:, 1], color="blue")
plt.plot(line_x, line_y, color="green")

plt.xlim([0, 45])
plt.ylim([0, 75])
plt.ylabel("длина")
plt.xlabel("ширина")
plt.grid(True)
plt.show()
